autoscaler:
  model_name: "BERT-large"
  training_label: "bert_large_elastic"
  s3_bucket: "mansmane-us-west-2"
  log_dir: "/fsx/logs/autoscaler_logs"
  enable_debug: Off
  collect_tensorboard: On
  world_size: 0
  reset_optimizer_state_on_restart: On
  cluster_state_update_interval: 500
  update_interval: 1
  precondition_gradients: On
  gradient_accumulation_supported: True
  adjust_gradients_for_accumulation: False
  smoothing: 0.1
adascale:
  aggressive_schedule: Off
  is_adaptive: True
  use_pt_adam: False
  max_grad_norm: 5.0
  adjust_momentum: False
gradient_noise_scale:
  batch_size_upper_limit: .Inf
  scale_one_batch_size: 65536
  # scale one world size for phase1 = 32 gpus X 32 gradient accumulation steps
  # Scale for base batch size 64k
  scale_one_world_size: 1024
