{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "political-supplement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: tensorboard in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (2.5.0)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (1.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorboard) (3.15.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorboard) (49.6.0.post20210108)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from tensorboard) (0.13.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from tensorboard) (1.33.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from tensorboard) (1.32.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorboard) (2.25.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorboard) (0.36.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from tensorboard) (0.4.4)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorboard) (1.18.5)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/cpu/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: matplotlib in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (3.3.4)\n",
      "Requirement already satisfied: seaborn in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (0.11.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from matplotlib) (8.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from seaborn) (1.6.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from seaborn) (1.2.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard pandas\n",
    "!pip install matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "subjective-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noticed-suspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard version:  2.5.0\n"
     ]
    }
   ],
   "source": [
    "major_ver, minor_ver, _ = version.parse(tb.__version__).release\n",
    "assert major_ver >= 2 and minor_ver >= 3, \\\n",
    "    \"This notebook requires TensorBoard 2.3 or later.\"\n",
    "print(\"TensorBoard version: \", tb.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specialized-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tb_data(root_dir, sort_by=None):\n",
    "    \"\"\"Convert local TensorBoard data into Pandas DataFrame.\n",
    "    \n",
    "    Function takes the root directory path and recursively parses\n",
    "    all events data.    \n",
    "    If the `sort_by` value is provided then it will use that column\n",
    "    to sort values; typically `wall_time` or `step`.\n",
    "    \n",
    "    *Note* that the whole data is converted into a DataFrame.\n",
    "    Depending on the data size this might take a while. If it takes\n",
    "    too long then narrow it to some sub-directories.\n",
    "    \n",
    "    Paramters:\n",
    "        root_dir: (str) path to root dir with tensorboard data.\n",
    "        sort_by: (optional str) column name to sort by.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame with [wall_time, name, step, value] columns.\n",
    "    \n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "\n",
    "    def convert_tfevent(filepath):\n",
    "        return pd.DataFrame([\n",
    "            parse_tfevent(e) for e in summary_iterator(filepath) if len(e.summary.value)\n",
    "        ])\n",
    "\n",
    "    def parse_tfevent(tfevent):\n",
    "        return dict(\n",
    "            wall_time=tfevent.wall_time,\n",
    "            name=tfevent.summary.value[0].tag,\n",
    "            step=tfevent.step,\n",
    "            value=float(tfevent.summary.value[0].simple_value),\n",
    "        )\n",
    "    \n",
    "    columns_order = ['wall_time', 'name', 'step', 'value']\n",
    "    \n",
    "    out = []\n",
    "    for (root, _, filenames) in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if \"events.out.tfevents\" not in filename:\n",
    "                continue\n",
    "            file_full_path = os.path.join(root, filename)\n",
    "            out.append(convert_tfevent(file_full_path))\n",
    "\n",
    "    # Concatenate (and sort) all partial individual dataframes\n",
    "    all_df = pd.concat(out)[columns_order]\n",
    "    if sort_by is not None:\n",
    "        all_df = all_df.sort_values(sort_by)\n",
    "        \n",
    "    return all_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "laden-average",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      wall_time                   name  step         value\n",
      "0  1.635898e+09  Train/Real Iterations     1  1.000000e+00\n",
      "1  1.635898e+09             Train/Loss     1  1.127476e+01\n",
      "2  1.635898e+09    Train/Learning Rate     1  3.410169e-10\n",
      "3  1.635898e+09             Train/Gain     1  1.000000e+00\n",
      "4  1.635898e+09              Train/GNS     1  0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"/fsx/code/gradstats/BERT/results/pretrain_large_4node_adam_grad_clipping_2norm_1_monitoring/tensorboard_phase1/bert_training\"\n",
    "exp_name = \"worker-0\"\n",
    "df = convert_tb_data(f\"{dir_path}/{exp_name}\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fantastic-niger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wall_time</th>\n",
       "      <th>name</th>\n",
       "      <th>step</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.635898e+09</td>\n",
       "      <td>Train/Real Iterations</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.635898e+09</td>\n",
       "      <td>Train/Loss</td>\n",
       "      <td>1</td>\n",
       "      <td>1.127476e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.635898e+09</td>\n",
       "      <td>Train/Learning Rate</td>\n",
       "      <td>1</td>\n",
       "      <td>3.410169e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.635898e+09</td>\n",
       "      <td>Train/Gain</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.635898e+09</td>\n",
       "      <td>Train/GNS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318269</th>\n",
       "      <td>1.636049e+09</td>\n",
       "      <td>Train/weight_key_Inf_norm</td>\n",
       "      <td>4301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318270</th>\n",
       "      <td>1.636049e+09</td>\n",
       "      <td>Train/weight_value_Inf_norm</td>\n",
       "      <td>4301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318271</th>\n",
       "      <td>1.636049e+09</td>\n",
       "      <td>Train/weight_dense_act_Inf_norm</td>\n",
       "      <td>4301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318272</th>\n",
       "      <td>1.636049e+09</td>\n",
       "      <td>Train/weight_LayerNorm_act_Inf_norm</td>\n",
       "      <td>4301</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318273</th>\n",
       "      <td>1.636049e+09</td>\n",
       "      <td>Train/total_grad_norm</td>\n",
       "      <td>4301</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318274 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           wall_time                                 name  step         value\n",
       "0       1.635898e+09                Train/Real Iterations     1  1.000000e+00\n",
       "1       1.635898e+09                           Train/Loss     1  1.127476e+01\n",
       "2       1.635898e+09                  Train/Learning Rate     1  3.410169e-10\n",
       "3       1.635898e+09                           Train/Gain     1  1.000000e+00\n",
       "4       1.635898e+09                            Train/GNS     1  0.000000e+00\n",
       "...              ...                                  ...   ...           ...\n",
       "318269  1.636049e+09            Train/weight_key_Inf_norm  4301  0.000000e+00\n",
       "318270  1.636049e+09          Train/weight_value_Inf_norm  4301  0.000000e+00\n",
       "318271  1.636049e+09      Train/weight_dense_act_Inf_norm  4301  0.000000e+00\n",
       "318272  1.636049e+09  Train/weight_LayerNorm_act_Inf_norm  4301  0.000000e+00\n",
       "318273  1.636049e+09                Train/total_grad_norm  4301           NaN\n",
       "\n",
       "[318274 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "residential-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sunrise-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_df_lst = grouped_df[\"value\"].apply(list)\n",
    "\n",
    "grouped_df_lst = grouped_df_lst.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "closing-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train/Effective LR</td>\n",
       "      <td>[3.410168536444047e-10, 1.3640674145776188e-09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train/GNS</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train/Gain</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train/Learning Rate</td>\n",
       "      <td>[3.410168536444047e-10, 1.3640674145776188e-09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train/Loss</td>\n",
       "      <td>[11.274764060974121, 11.280522346496582, 11.27...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                                              value\n",
       "0   Train/Effective LR  [3.410168536444047e-10, 1.3640674145776188e-09...\n",
       "1            Train/GNS  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2           Train/Gain  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "3  Train/Learning Rate  [3.410168536444047e-10, 1.3640674145776188e-09...\n",
       "4           Train/Loss  [11.274764060974121, 11.280522346496582, 11.27..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_lst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "confident-lithuania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train/Effective LR</td>\n",
       "      <td>[3.410168536444047e-10, 1.3640674145776188e-09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train/GNS</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train/Gain</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train/Learning Rate</td>\n",
       "      <td>[3.410168536444047e-10, 1.3640674145776188e-09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train/Loss</td>\n",
       "      <td>[11.274764060974121, 11.280522346496582, 11.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Train/weight_layer_8_2norm</td>\n",
       "      <td>[82.25440979003906, 82.25440979003906, 82.2544...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Train/weight_layer_9_2norm</td>\n",
       "      <td>[82.26065063476562, 82.26065063476562, 82.2606...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Train/weight_pooler_2norm</td>\n",
       "      <td>[18.48503303527832, 18.48503303527832, 18.4850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Train/weight_query_Inf_norm</td>\n",
       "      <td>[0.1113998219370842, 0.1113998219370842, 0.111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Train/weight_value_Inf_norm</td>\n",
       "      <td>[0.11276709288358688, 0.11276709288358688, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0            Train/Effective LR   \n",
       "1                     Train/GNS   \n",
       "2                    Train/Gain   \n",
       "3           Train/Learning Rate   \n",
       "4                    Train/Loss   \n",
       "..                          ...   \n",
       "69   Train/weight_layer_8_2norm   \n",
       "70   Train/weight_layer_9_2norm   \n",
       "71    Train/weight_pooler_2norm   \n",
       "72  Train/weight_query_Inf_norm   \n",
       "73  Train/weight_value_Inf_norm   \n",
       "\n",
       "                                                value  \n",
       "0   [3.410168536444047e-10, 1.3640674145776188e-09...  \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "3   [3.410168536444047e-10, 1.3640674145776188e-09...  \n",
       "4   [11.274764060974121, 11.280522346496582, 11.27...  \n",
       "..                                                ...  \n",
       "69  [82.25440979003906, 82.25440979003906, 82.2544...  \n",
       "70  [82.26065063476562, 82.26065063476562, 82.2606...  \n",
       "71  [18.48503303527832, 18.48503303527832, 18.4850...  \n",
       "72  [0.1113998219370842, 0.1113998219370842, 0.111...  \n",
       "73  [0.11276709288358688, 0.11276709288358688, 0.1...  \n",
       "\n",
       "[74 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "guilty-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_nan_index(row):\n",
    "    value_list = row['value']\n",
    "    from math import isnan\n",
    "    for i in range(len(value_list)):\n",
    "        if isnan(value_list[i]):\n",
    "            return i\n",
    "    return i\n",
    "        \n",
    "#    return lst.index(next(filter(lambda x:  isnan(x), lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "sealed-issue",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "find_first_nan_index() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-d3b79f973e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfind_first_nan_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'junk'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: find_first_nan_index() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "lst = [1.0,0, 3, float('nan'), float('nan'), 5.5, 5.0, 5.0, 5.5, 6.0, 6.5]\n",
    "find_first_nan_index('junk',lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "lucky-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_lst['first_nan_idx'] = grouped_df_lst.apply(find_first_nan_index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "medieval-david",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4300\n",
       "1     4300\n",
       "2     4300\n",
       "3     4300\n",
       "4     1134\n",
       "      ... \n",
       "69    2435\n",
       "70    2435\n",
       "71    2435\n",
       "72    4300\n",
       "73    4300\n",
       "Name: first_nan_idx, Length: 74, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_lst['first_nan_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "informal-throat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "      <th>first_nan_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train/Effective LR</td>\n",
       "      <td>[3.410168536444047e-10, 1.3640674145776188e-09...</td>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train/GNS</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train/Gain</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train/Learning Rate</td>\n",
       "      <td>[3.410168536444047e-10, 1.3640674145776188e-09...</td>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train/Loss</td>\n",
       "      <td>[11.274764060974121, 11.280522346496582, 11.27...</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Train/weight_layer_8_2norm</td>\n",
       "      <td>[82.25440979003906, 82.25440979003906, 82.2544...</td>\n",
       "      <td>2435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Train/weight_layer_9_2norm</td>\n",
       "      <td>[82.26065063476562, 82.26065063476562, 82.2606...</td>\n",
       "      <td>2435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Train/weight_pooler_2norm</td>\n",
       "      <td>[18.48503303527832, 18.48503303527832, 18.4850...</td>\n",
       "      <td>2435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Train/weight_query_Inf_norm</td>\n",
       "      <td>[0.1113998219370842, 0.1113998219370842, 0.111...</td>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Train/weight_value_Inf_norm</td>\n",
       "      <td>[0.11276709288358688, 0.11276709288358688, 0.1...</td>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0            Train/Effective LR   \n",
       "1                     Train/GNS   \n",
       "2                    Train/Gain   \n",
       "3           Train/Learning Rate   \n",
       "4                    Train/Loss   \n",
       "..                          ...   \n",
       "69   Train/weight_layer_8_2norm   \n",
       "70   Train/weight_layer_9_2norm   \n",
       "71    Train/weight_pooler_2norm   \n",
       "72  Train/weight_query_Inf_norm   \n",
       "73  Train/weight_value_Inf_norm   \n",
       "\n",
       "                                                value  first_nan_idx  \n",
       "0   [3.410168536444047e-10, 1.3640674145776188e-09...           4300  \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           4300  \n",
       "2   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...           4300  \n",
       "3   [3.410168536444047e-10, 1.3640674145776188e-09...           4300  \n",
       "4   [11.274764060974121, 11.280522346496582, 11.27...           1134  \n",
       "..                                                ...            ...  \n",
       "69  [82.25440979003906, 82.25440979003906, 82.2544...           2435  \n",
       "70  [82.26065063476562, 82.26065063476562, 82.2606...           2435  \n",
       "71  [18.48503303527832, 18.48503303527832, 18.4850...           2435  \n",
       "72  [0.1113998219370842, 0.1113998219370842, 0.111...           4300  \n",
       "73  [0.11276709288358688, 0.11276709288358688, 0.1...           4300  \n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "royal-advantage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " type(grouped_df_lst['value'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "strategic-registrar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_nan_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2327.527027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1293.902626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1099.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2435.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2435.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_nan_idx\n",
       "count      74.000000\n",
       "mean     2327.527027\n",
       "std      1293.902626\n",
       "min       608.000000\n",
       "25%      1099.000000\n",
       "50%      2435.000000\n",
       "75%      2435.000000\n",
       "max      4300.000000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_lst.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-reception",
   "metadata": {},
   "source": [
    "## First occurance of NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "competent-software",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          name  \\\n",
      "10  Train/grad_embedding_2norm   \n",
      "13    Train/grad_layer_0_2norm   \n",
      "24    Train/grad_layer_1_2norm   \n",
      "29    Train/grad_layer_2_2norm   \n",
      "40       Train/total_grad_norm   \n",
      "\n",
      "                                                value  first_nan_idx  \n",
      "10  [103.29421997070312, 103.53217315673828, 103.4...            608  \n",
      "13  [54.35948944091797, 54.52595138549805, 54.6853...            608  \n",
      "24  [241.9202423095703, 243.14605712890625, 244.24...            608  \n",
      "29  [167.96266174316406, 168.76881408691406, 169.7...            608  \n",
      "40  [376.041015625, 377.8873596191406, 379.7981262...            608  \n"
     ]
    }
   ],
   "source": [
    "print(grouped_df_lst[grouped_df_lst.first_nan_idx == grouped_df_lst.first_nan_idx.min()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-brunswick",
   "metadata": {},
   "source": [
    "## Gradient norms ranked by magniture at step 607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "controlled-chosen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "      <th>first_nan_idx</th>\n",
       "      <th>607</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train/Real Iterations</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>4300</td>\n",
       "      <td>608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Train/weight_layer_1_2norm</td>\n",
       "      <td>[272.88458251953125, 272.88458251953125, 272.8...</td>\n",
       "      <td>2435</td>\n",
       "      <td>271.936127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Train/weight_layer_2_2norm</td>\n",
       "      <td>[183.98777770996094, 183.98777770996094, 183.9...</td>\n",
       "      <td>2435</td>\n",
       "      <td>183.388824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Train/weight_embedding_2norm</td>\n",
       "      <td>[117.20905303955078, 117.20905303955078, 117.2...</td>\n",
       "      <td>2435</td>\n",
       "      <td>120.030708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Train/weight_layer_0_2norm</td>\n",
       "      <td>[82.29265594482422, 82.29265594482422, 82.2926...</td>\n",
       "      <td>2435</td>\n",
       "      <td>82.082260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Train/weight_layer_3_2norm</td>\n",
       "      <td>[82.27923583984375, 82.27923583984375, 82.2792...</td>\n",
       "      <td>2435</td>\n",
       "      <td>82.058441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Train/weight_layer_6_2norm</td>\n",
       "      <td>[82.284912109375, 82.284912109375, 82.28491210...</td>\n",
       "      <td>2435</td>\n",
       "      <td>82.020607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Train/weight_layer_22_2norm</td>\n",
       "      <td>[82.28385925292969, 82.28385925292969, 82.2838...</td>\n",
       "      <td>2435</td>\n",
       "      <td>82.017845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Train/weight_layer_10_2norm</td>\n",
       "      <td>[82.29765319824219, 82.29765319824219, 82.2976...</td>\n",
       "      <td>2435</td>\n",
       "      <td>82.015007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Train/weight_layer_5_2norm</td>\n",
       "      <td>[82.27030944824219, 82.27030944824219, 82.2703...</td>\n",
       "      <td>2435</td>\n",
       "      <td>82.012695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Train/weight_layer_4_2norm</td>\n",
       "      <td>[82.24699401855469, 82.24699401855469, 82.2469...</td>\n",
       "      <td>2435</td>\n",
       "      <td>82.012581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Train/weight_layer_21_2norm</td>\n",
       "      <td>[82.29169464111328, 82.29169464111328, 82.2916...</td>\n",
       "      <td>2435</td>\n",
       "      <td>82.011086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Train/weight_layer_17_2norm</td>\n",
       "      <td>[82.29190826416016, 82.29190826416016, 82.2919...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.993065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Train/weight_layer_7_2norm</td>\n",
       "      <td>[82.25839233398438, 82.25839233398438, 82.2583...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.990829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Train/weight_layer_23_2norm</td>\n",
       "      <td>[82.2684097290039, 82.2684097290039, 82.268409...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.990219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Train/weight_layer_14_2norm</td>\n",
       "      <td>[82.2805404663086, 82.2805404663086, 82.280540...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.989021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Train/weight_layer_20_2norm</td>\n",
       "      <td>[82.27843475341797, 82.27843475341797, 82.2784...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.986763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Train/weight_layer_19_2norm</td>\n",
       "      <td>[82.28382873535156, 82.28382873535156, 82.2838...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.986259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Train/weight_layer_11_2norm</td>\n",
       "      <td>[82.27164459228516, 82.27164459228516, 82.2716...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.984474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Train/weight_layer_12_2norm</td>\n",
       "      <td>[82.26944732666016, 82.26944732666016, 82.2694...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.979126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Train/weight_layer_8_2norm</td>\n",
       "      <td>[82.25440979003906, 82.25440979003906, 82.2544...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.978439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Train/weight_layer_9_2norm</td>\n",
       "      <td>[82.26065063476562, 82.26065063476562, 82.2606...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.978432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Train/weight_layer_15_2norm</td>\n",
       "      <td>[82.27185821533203, 82.27185821533203, 82.2718...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.977493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Train/weight_layer_13_2norm</td>\n",
       "      <td>[82.2699203491211, 82.2699203491211, 82.269920...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.976334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Train/weight_layer_16_2norm</td>\n",
       "      <td>[82.26606750488281, 82.26606750488281, 82.2660...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.973167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Train/weight_layer_18_2norm</td>\n",
       "      <td>[82.26578521728516, 82.26578521728516, 82.2657...</td>\n",
       "      <td>2435</td>\n",
       "      <td>81.965317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Train/weight_cls_2norm</td>\n",
       "      <td>[36.97435760498047, 36.97435760498047, 36.9743...</td>\n",
       "      <td>2435</td>\n",
       "      <td>75.174728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Train/total_grad_norm</td>\n",
       "      <td>[376.041015625, 377.8873596191406, 379.7981262...</td>\n",
       "      <td>608</td>\n",
       "      <td>50.497585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Train/grad_embedding_2norm</td>\n",
       "      <td>[103.29421997070312, 103.53217315673828, 103.4...</td>\n",
       "      <td>608</td>\n",
       "      <td>38.097675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Train/grad_cls_2norm</td>\n",
       "      <td>[105.2564926147461, 105.62910461425781, 106.10...</td>\n",
       "      <td>1099</td>\n",
       "      <td>22.694250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "5          Train/Real Iterations   \n",
       "58    Train/weight_layer_1_2norm   \n",
       "63    Train/weight_layer_2_2norm   \n",
       "44  Train/weight_embedding_2norm   \n",
       "47    Train/weight_layer_0_2norm   \n",
       "64    Train/weight_layer_3_2norm   \n",
       "67    Train/weight_layer_6_2norm   \n",
       "61   Train/weight_layer_22_2norm   \n",
       "48   Train/weight_layer_10_2norm   \n",
       "66    Train/weight_layer_5_2norm   \n",
       "65    Train/weight_layer_4_2norm   \n",
       "60   Train/weight_layer_21_2norm   \n",
       "55   Train/weight_layer_17_2norm   \n",
       "68    Train/weight_layer_7_2norm   \n",
       "62   Train/weight_layer_23_2norm   \n",
       "52   Train/weight_layer_14_2norm   \n",
       "59   Train/weight_layer_20_2norm   \n",
       "57   Train/weight_layer_19_2norm   \n",
       "49   Train/weight_layer_11_2norm   \n",
       "50   Train/weight_layer_12_2norm   \n",
       "69    Train/weight_layer_8_2norm   \n",
       "70    Train/weight_layer_9_2norm   \n",
       "53   Train/weight_layer_15_2norm   \n",
       "51   Train/weight_layer_13_2norm   \n",
       "54   Train/weight_layer_16_2norm   \n",
       "56   Train/weight_layer_18_2norm   \n",
       "42        Train/weight_cls_2norm   \n",
       "40         Train/total_grad_norm   \n",
       "10    Train/grad_embedding_2norm   \n",
       "8           Train/grad_cls_2norm   \n",
       "\n",
       "                                                value  first_nan_idx  \\\n",
       "5   [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...           4300   \n",
       "58  [272.88458251953125, 272.88458251953125, 272.8...           2435   \n",
       "63  [183.98777770996094, 183.98777770996094, 183.9...           2435   \n",
       "44  [117.20905303955078, 117.20905303955078, 117.2...           2435   \n",
       "47  [82.29265594482422, 82.29265594482422, 82.2926...           2435   \n",
       "64  [82.27923583984375, 82.27923583984375, 82.2792...           2435   \n",
       "67  [82.284912109375, 82.284912109375, 82.28491210...           2435   \n",
       "61  [82.28385925292969, 82.28385925292969, 82.2838...           2435   \n",
       "48  [82.29765319824219, 82.29765319824219, 82.2976...           2435   \n",
       "66  [82.27030944824219, 82.27030944824219, 82.2703...           2435   \n",
       "65  [82.24699401855469, 82.24699401855469, 82.2469...           2435   \n",
       "60  [82.29169464111328, 82.29169464111328, 82.2916...           2435   \n",
       "55  [82.29190826416016, 82.29190826416016, 82.2919...           2435   \n",
       "68  [82.25839233398438, 82.25839233398438, 82.2583...           2435   \n",
       "62  [82.2684097290039, 82.2684097290039, 82.268409...           2435   \n",
       "52  [82.2805404663086, 82.2805404663086, 82.280540...           2435   \n",
       "59  [82.27843475341797, 82.27843475341797, 82.2784...           2435   \n",
       "57  [82.28382873535156, 82.28382873535156, 82.2838...           2435   \n",
       "49  [82.27164459228516, 82.27164459228516, 82.2716...           2435   \n",
       "50  [82.26944732666016, 82.26944732666016, 82.2694...           2435   \n",
       "69  [82.25440979003906, 82.25440979003906, 82.2544...           2435   \n",
       "70  [82.26065063476562, 82.26065063476562, 82.2606...           2435   \n",
       "53  [82.27185821533203, 82.27185821533203, 82.2718...           2435   \n",
       "51  [82.2699203491211, 82.2699203491211, 82.269920...           2435   \n",
       "54  [82.26606750488281, 82.26606750488281, 82.2660...           2435   \n",
       "56  [82.26578521728516, 82.26578521728516, 82.2657...           2435   \n",
       "42  [36.97435760498047, 36.97435760498047, 36.9743...           2435   \n",
       "40  [376.041015625, 377.8873596191406, 379.7981262...            608   \n",
       "10  [103.29421997070312, 103.53217315673828, 103.4...            608   \n",
       "8   [105.2564926147461, 105.62910461425781, 106.10...           1099   \n",
       "\n",
       "           607  \n",
       "5   608.000000  \n",
       "58  271.936127  \n",
       "63  183.388824  \n",
       "44  120.030708  \n",
       "47   82.082260  \n",
       "64   82.058441  \n",
       "67   82.020607  \n",
       "61   82.017845  \n",
       "48   82.015007  \n",
       "66   82.012695  \n",
       "65   82.012581  \n",
       "60   82.011086  \n",
       "55   81.993065  \n",
       "68   81.990829  \n",
       "62   81.990219  \n",
       "52   81.989021  \n",
       "59   81.986763  \n",
       "57   81.986259  \n",
       "49   81.984474  \n",
       "50   81.979126  \n",
       "69   81.978439  \n",
       "70   81.978432  \n",
       "53   81.977493  \n",
       "51   81.976334  \n",
       "54   81.973167  \n",
       "56   81.965317  \n",
       "42   75.174728  \n",
       "40   50.497585  \n",
       "10   38.097675  \n",
       "8    22.694250  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_lst['607'] = grouped_df_lst.apply(lambda a: a['value'][607],  axis=1)\n",
    "grouped_df_lst_sorted = grouped_df_lst.sort_values([\"607\"], ascending=False)\n",
    "grouped_df_lst_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "expanded-treatment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "      <th>first_nan_idx</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train/Real Iterations</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>4300</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>609.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Train/weight_layer_1_2norm</td>\n",
       "      <td>[272.88458251953125, 272.88458251953125, 272.8...</td>\n",
       "      <td>2435</td>\n",
       "      <td>271.936127</td>\n",
       "      <td>271.931732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Train/weight_layer_2_2norm</td>\n",
       "      <td>[183.98777770996094, 183.98777770996094, 183.9...</td>\n",
       "      <td>2435</td>\n",
       "      <td>183.388824</td>\n",
       "      <td>183.385788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Train/weight_embedding_2norm</td>\n",
       "      <td>[117.20905303955078, 117.20905303955078, 117.2...</td>\n",
       "      <td>2435</td>\n",
       "      <td>120.030708</td>\n",
       "      <td>120.033615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Train/weight_layer_0_2norm</td>\n",
       "      <td>[82.29265594482422, 82.29265594482422, 82.2926...</td>\n",
       "      <td>2435</td>\n",
       "      <td>82.082260</td>\n",
       "      <td>82.081322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train/GNS</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>4300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Train/grad_embedding_2norm</td>\n",
       "      <td>[103.29421997070312, 103.53217315673828, 103.4...</td>\n",
       "      <td>608</td>\n",
       "      <td>38.097675</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Train/grad_layer_0_2norm</td>\n",
       "      <td>[54.35948944091797, 54.52595138549805, 54.6853...</td>\n",
       "      <td>608</td>\n",
       "      <td>13.281496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Train/grad_layer_1_2norm</td>\n",
       "      <td>[241.9202423095703, 243.14605712890625, 244.24...</td>\n",
       "      <td>608</td>\n",
       "      <td>6.631056</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Train/grad_layer_2_2norm</td>\n",
       "      <td>[167.96266174316406, 168.76881408691406, 169.7...</td>\n",
       "      <td>608</td>\n",
       "      <td>8.355430</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "5          Train/Real Iterations   \n",
       "58    Train/weight_layer_1_2norm   \n",
       "63    Train/weight_layer_2_2norm   \n",
       "44  Train/weight_embedding_2norm   \n",
       "47    Train/weight_layer_0_2norm   \n",
       "..                           ...   \n",
       "1                      Train/GNS   \n",
       "10    Train/grad_embedding_2norm   \n",
       "13      Train/grad_layer_0_2norm   \n",
       "24      Train/grad_layer_1_2norm   \n",
       "29      Train/grad_layer_2_2norm   \n",
       "\n",
       "                                                value  first_nan_idx  \\\n",
       "5   [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...           4300   \n",
       "58  [272.88458251953125, 272.88458251953125, 272.8...           2435   \n",
       "63  [183.98777770996094, 183.98777770996094, 183.9...           2435   \n",
       "44  [117.20905303955078, 117.20905303955078, 117.2...           2435   \n",
       "47  [82.29265594482422, 82.29265594482422, 82.2926...           2435   \n",
       "..                                                ...            ...   \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           4300   \n",
       "10  [103.29421997070312, 103.53217315673828, 103.4...            608   \n",
       "13  [54.35948944091797, 54.52595138549805, 54.6853...            608   \n",
       "24  [241.9202423095703, 243.14605712890625, 244.24...            608   \n",
       "29  [167.96266174316406, 168.76881408691406, 169.7...            608   \n",
       "\n",
       "           607         608  \n",
       "5   608.000000  609.000000  \n",
       "58  271.936127  271.931732  \n",
       "63  183.388824  183.385788  \n",
       "44  120.030708  120.033615  \n",
       "47   82.082260   82.081322  \n",
       "..         ...         ...  \n",
       "1     0.000000    0.000000  \n",
       "10   38.097675         NaN  \n",
       "13   13.281496         NaN  \n",
       "24    6.631056         NaN  \n",
       "29    8.355430         NaN  \n",
       "\n",
       "[73 rows x 5 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_lst['608'] = grouped_df_lst.apply(lambda a: a['value'][608],  axis=1)\n",
    "grouped_df_lst_sorted = grouped_df_lst.sort_values([\"608\"], ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "moral-qatar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "      <th>first_nan_idx</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train/Real Iterations</td>\n",
       "      <td>[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>4300</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>609.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Train/weight_layer_1_2norm</td>\n",
       "      <td>[272.88458251953125, 272.88458251953125, 272.8...</td>\n",
       "      <td>2435</td>\n",
       "      <td>271.936127</td>\n",
       "      <td>271.931732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Train/weight_layer_2_2norm</td>\n",
       "      <td>[183.98777770996094, 183.98777770996094, 183.9...</td>\n",
       "      <td>2435</td>\n",
       "      <td>183.388824</td>\n",
       "      <td>183.385788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Train/weight_embedding_2norm</td>\n",
       "      <td>[117.20905303955078, 117.20905303955078, 117.2...</td>\n",
       "      <td>2435</td>\n",
       "      <td>120.030708</td>\n",
       "      <td>120.033615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Train/weight_layer_0_2norm</td>\n",
       "      <td>[82.29265594482422, 82.29265594482422, 82.2926...</td>\n",
       "      <td>2435</td>\n",
       "      <td>82.082260</td>\n",
       "      <td>82.081322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train/GNS</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>4300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Train/grad_embedding_2norm</td>\n",
       "      <td>[103.29421997070312, 103.53217315673828, 103.4...</td>\n",
       "      <td>608</td>\n",
       "      <td>38.097675</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Train/grad_layer_0_2norm</td>\n",
       "      <td>[54.35948944091797, 54.52595138549805, 54.6853...</td>\n",
       "      <td>608</td>\n",
       "      <td>13.281496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Train/grad_layer_1_2norm</td>\n",
       "      <td>[241.9202423095703, 243.14605712890625, 244.24...</td>\n",
       "      <td>608</td>\n",
       "      <td>6.631056</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Train/grad_layer_2_2norm</td>\n",
       "      <td>[167.96266174316406, 168.76881408691406, 169.7...</td>\n",
       "      <td>608</td>\n",
       "      <td>8.355430</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "5          Train/Real Iterations   \n",
       "58    Train/weight_layer_1_2norm   \n",
       "63    Train/weight_layer_2_2norm   \n",
       "44  Train/weight_embedding_2norm   \n",
       "47    Train/weight_layer_0_2norm   \n",
       "..                           ...   \n",
       "1                      Train/GNS   \n",
       "10    Train/grad_embedding_2norm   \n",
       "13      Train/grad_layer_0_2norm   \n",
       "24      Train/grad_layer_1_2norm   \n",
       "29      Train/grad_layer_2_2norm   \n",
       "\n",
       "                                                value  first_nan_idx  \\\n",
       "5   [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...           4300   \n",
       "58  [272.88458251953125, 272.88458251953125, 272.8...           2435   \n",
       "63  [183.98777770996094, 183.98777770996094, 183.9...           2435   \n",
       "44  [117.20905303955078, 117.20905303955078, 117.2...           2435   \n",
       "47  [82.29265594482422, 82.29265594482422, 82.2926...           2435   \n",
       "..                                                ...            ...   \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           4300   \n",
       "10  [103.29421997070312, 103.53217315673828, 103.4...            608   \n",
       "13  [54.35948944091797, 54.52595138549805, 54.6853...            608   \n",
       "24  [241.9202423095703, 243.14605712890625, 244.24...            608   \n",
       "29  [167.96266174316406, 168.76881408691406, 169.7...            608   \n",
       "\n",
       "           607         608  \n",
       "5   608.000000  609.000000  \n",
       "58  271.936127  271.931732  \n",
       "63  183.388824  183.385788  \n",
       "44  120.030708  120.033615  \n",
       "47   82.082260   82.081322  \n",
       "..         ...         ...  \n",
       "1     0.000000    0.000000  \n",
       "10   38.097675         NaN  \n",
       "13   13.281496         NaN  \n",
       "24    6.631056         NaN  \n",
       "29    8.355430         NaN  \n",
       "\n",
       "[73 rows x 5 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_lst_sorted.head(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ready-recruitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   name  first_nan_idx         607         608\n",
      "5                 Train/Real Iterations           4300  608.000000  609.000000\n",
      "58           Train/weight_layer_1_2norm           2435  271.936127  271.931732\n",
      "63           Train/weight_layer_2_2norm           2435  183.388824  183.385788\n",
      "44         Train/weight_embedding_2norm           2435  120.030708  120.033615\n",
      "47           Train/weight_layer_0_2norm           2435   82.082260   82.081322\n",
      "64           Train/weight_layer_3_2norm           2435   82.058441   82.057350\n",
      "67           Train/weight_layer_6_2norm           2435   82.020607   82.019333\n",
      "61          Train/weight_layer_22_2norm           2435   82.017845   82.016388\n",
      "48          Train/weight_layer_10_2norm           2435   82.015007   82.013657\n",
      "65           Train/weight_layer_4_2norm           2435   82.012581   82.011475\n",
      "66           Train/weight_layer_5_2norm           2435   82.012695   82.011452\n",
      "60          Train/weight_layer_21_2norm           2435   82.011086   82.009636\n",
      "55          Train/weight_layer_17_2norm           2435   81.993065   81.991669\n",
      "68           Train/weight_layer_7_2norm           2435   81.990829   81.989540\n",
      "62          Train/weight_layer_23_2norm           2435   81.990219   81.988861\n",
      "52          Train/weight_layer_14_2norm           2435   81.989021   81.987701\n",
      "59          Train/weight_layer_20_2norm           2435   81.986763   81.985313\n",
      "57          Train/weight_layer_19_2norm           2435   81.986259   81.984764\n",
      "49          Train/weight_layer_11_2norm           2435   81.984474   81.983124\n",
      "50          Train/weight_layer_12_2norm           2435   81.979126   81.977783\n",
      "69           Train/weight_layer_8_2norm           2435   81.978439   81.977158\n",
      "70           Train/weight_layer_9_2norm           2435   81.978432   81.977135\n",
      "53          Train/weight_layer_15_2norm           2435   81.977493   81.976204\n",
      "51          Train/weight_layer_13_2norm           2435   81.976334   81.975037\n",
      "54          Train/weight_layer_16_2norm           2435   81.973167   81.971832\n",
      "56          Train/weight_layer_18_2norm           2435   81.965317   81.963875\n",
      "42               Train/weight_cls_2norm           2435   75.174728   75.176628\n",
      "71            Train/weight_pooler_2norm           2435   18.395102   18.394686\n",
      "8                  Train/grad_cls_2norm           1099   22.694250    8.092440\n",
      "4                            Train/Loss           1134    7.591934    7.572132\n",
      "37              Train/grad_pooler_2norm           1103   16.164764    5.557342\n",
      "28            Train/grad_layer_23_2norm           1099    5.236060    3.234051\n",
      "30             Train/grad_layer_3_2norm            885    3.100649    3.145219\n",
      "27            Train/grad_layer_22_2norm           1099    3.638629    2.709837\n",
      "31             Train/grad_layer_4_2norm            950    2.749049    2.426603\n",
      "26            Train/grad_layer_21_2norm           1099    3.167717    2.151530\n",
      "32             Train/grad_layer_5_2norm           1099    2.052094    1.478170\n",
      "25            Train/grad_layer_20_2norm           1099    2.456361    1.439656\n",
      "23            Train/grad_layer_19_2norm           1099    2.214928    1.113299\n",
      "41  Train/weight_LayerNorm_act_Inf_norm           4300    1.008860    1.008871\n",
      "45      Train/weight_embedding_Inf_norm           4300    1.004956    1.004970\n",
      "6                           Train/Scale           4300    1.000000    1.000000\n",
      "2                            Train/Gain           4300    1.000000    1.000000\n",
      "33             Train/grad_layer_6_2norm           1099    1.801063    0.982004\n",
      "34             Train/grad_layer_7_2norm           1099    1.680697    0.878587\n",
      "35             Train/grad_layer_8_2norm           1099    1.578135    0.817214\n",
      "22            Train/grad_layer_18_2norm           1099    1.843794    0.787899\n",
      "36             Train/grad_layer_9_2norm           1099    1.456332    0.743294\n",
      "14            Train/grad_layer_10_2norm           1099    1.344387    0.700638\n",
      "21            Train/grad_layer_17_2norm           1099    1.584466    0.676339\n",
      "15            Train/grad_layer_11_2norm           1099    1.358699    0.653256\n",
      "20            Train/grad_layer_16_2norm           1099    1.410423    0.610353\n",
      "16            Train/grad_layer_12_2norm           1099    1.346042    0.604570\n",
      "18            Train/grad_layer_14_2norm           1099    1.306418    0.604090\n",
      "11        Train/grad_embedding_Inf_norm           4300    3.943117    0.599954\n",
      "17            Train/grad_layer_13_2norm           1099    1.304716    0.583358\n",
      "19            Train/grad_layer_15_2norm           1099    1.389920    0.554338\n",
      "43      Train/weight_dense_act_Inf_norm           4300    0.114814    0.114820\n",
      "73          Train/weight_value_Inf_norm           4300    0.112085    0.112079\n",
      "72          Train/weight_query_Inf_norm           4300    0.111351    0.111334\n",
      "46            Train/weight_key_Inf_norm           4300    0.109772    0.109751\n",
      "7     Train/grad_LayerNorm_act_Inf_norm           4300    0.122607    0.046559\n",
      "9         Train/grad_dense_act_Inf_norm           4300    0.096706    0.038143\n",
      "39            Train/grad_value_Inf_norm           4300    0.168569    0.025353\n",
      "12              Train/grad_key_Inf_norm           4300    0.081270    0.019245\n",
      "38            Train/grad_query_Inf_norm           4300    0.035179    0.015035\n",
      "3                   Train/Learning Rate           4300    0.000126    0.000126\n",
      "0                    Train/Effective LR           4300    0.000126    0.000126\n",
      "1                             Train/GNS           4300    0.000000    0.000000\n",
      "10           Train/grad_embedding_2norm            608   38.097675         NaN\n",
      "13             Train/grad_layer_0_2norm            608   13.281496         NaN\n",
      "24             Train/grad_layer_1_2norm            608    6.631056         NaN\n",
      "29             Train/grad_layer_2_2norm            608    8.355430         NaN\n",
      "40                Train/total_grad_norm            608   50.497585         NaN\n"
     ]
    }
   ],
   "source": [
    "#pd.set_option('display.max_rows', 73)\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(grouped_df_lst_sorted[['name', 'first_nan_idx', '607','608']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "concerned-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Grads vs layers\n",
    "def remove_chars(row):\n",
    "    import re\n",
    "    if 'pooler' in row['name'] or 'cls' in row['name']:\n",
    "        return 25\n",
    "    if 'embedding' in row['name']:\n",
    "        return -1\n",
    "\n",
    "    \n",
    "    a = re.sub('2norm', '', row['name'])\n",
    "    b = re.sub('\\D', '', a)\n",
    "    if b:\n",
    "        return int(b)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "grad_df = grouped_df_lst_sorted.set_index('name')\n",
    "grad_df = grad_df.filter(regex='grad_\\S*_2norm', axis=0)\n",
    "grad_df = grad_df.reset_index()\n",
    "grad_df['Layer'] = grad_df.apply(remove_chars, axis=1)\n",
    "grad_df = grad_df.sort_values([\"Layer\"], ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "printable-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Weights vs layers\n",
    "weight_df = grouped_df_lst_sorted.set_index('name')\n",
    "weight_df = weight_df.filter(regex='weight_\\S*_2norm', axis=0)\n",
    "weight_df = weight_df.reset_index()\n",
    "weight_df['Layer'] = weight_df.apply(remove_chars, axis=1)\n",
    "weight_df = weight_df.sort_values([\"Layer\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "civic-bangkok",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "weight_df_plot = weight_df[['Layer','607','608']]\n",
    "weight_df_plot.set_index('Layer')\n",
    "weight_df_plot.plot(x='Layer', y=['607','608']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "piano-palestine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "grad_df_plot = grad_df[['Layer','607','608']]\n",
    "grad_df_plot.set_index('Layer')\n",
    "grad_df_plot.plot(x='Layer', y=['607','608']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "infrared-council",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "      <th>first_nan_idx</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "      <th>Layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Train/grad_embedding_2norm</td>\n",
       "      <td>[103.29421997070312, 103.53217315673828, 103.4...</td>\n",
       "      <td>608</td>\n",
       "      <td>38.097675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Train/grad_layer_0_2norm</td>\n",
       "      <td>[54.35948944091797, 54.52595138549805, 54.6853...</td>\n",
       "      <td>608</td>\n",
       "      <td>13.281496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Train/grad_layer_1_2norm</td>\n",
       "      <td>[241.9202423095703, 243.14605712890625, 244.24...</td>\n",
       "      <td>608</td>\n",
       "      <td>6.631056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Train/grad_layer_2_2norm</td>\n",
       "      <td>[167.96266174316406, 168.76881408691406, 169.7...</td>\n",
       "      <td>608</td>\n",
       "      <td>8.355430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train/grad_layer_3_2norm</td>\n",
       "      <td>[62.93558883666992, 63.19911575317383, 63.6056...</td>\n",
       "      <td>885</td>\n",
       "      <td>3.100649</td>\n",
       "      <td>3.145219</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train/grad_layer_4_2norm</td>\n",
       "      <td>[63.615966796875, 63.90384292602539, 64.273933...</td>\n",
       "      <td>950</td>\n",
       "      <td>2.749049</td>\n",
       "      <td>2.426603</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Train/grad_layer_5_2norm</td>\n",
       "      <td>[62.18846893310547, 62.52492904663086, 62.8268...</td>\n",
       "      <td>1099</td>\n",
       "      <td>2.052094</td>\n",
       "      <td>1.478170</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Train/grad_layer_6_2norm</td>\n",
       "      <td>[61.07050704956055, 61.462486267089844, 61.727...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.801063</td>\n",
       "      <td>0.982004</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Train/grad_layer_7_2norm</td>\n",
       "      <td>[63.3437385559082, 63.75693130493164, 64.03693...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.680697</td>\n",
       "      <td>0.878587</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Train/grad_layer_8_2norm</td>\n",
       "      <td>[66.45199584960938, 66.84586334228516, 67.0798...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.578135</td>\n",
       "      <td>0.817214</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Train/grad_layer_9_2norm</td>\n",
       "      <td>[67.0876235961914, 67.46084594726562, 67.72129...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.456332</td>\n",
       "      <td>0.743294</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Train/grad_layer_10_2norm</td>\n",
       "      <td>[67.27655792236328, 67.66964721679688, 67.8567...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.344387</td>\n",
       "      <td>0.700638</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Train/grad_layer_11_2norm</td>\n",
       "      <td>[71.53353881835938, 71.94508361816406, 72.1277...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.358699</td>\n",
       "      <td>0.653256</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Train/grad_layer_12_2norm</td>\n",
       "      <td>[74.53720092773438, 74.94662475585938, 75.2658...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.346042</td>\n",
       "      <td>0.604570</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Train/grad_layer_13_2norm</td>\n",
       "      <td>[74.5763168334961, 74.93720245361328, 75.35667...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.304716</td>\n",
       "      <td>0.583358</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Train/grad_layer_14_2norm</td>\n",
       "      <td>[76.73747253417969, 77.13155364990234, 77.5105...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.306418</td>\n",
       "      <td>0.604090</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Train/grad_layer_15_2norm</td>\n",
       "      <td>[76.26922607421875, 76.68714141845703, 77.1190...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.389920</td>\n",
       "      <td>0.554338</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Train/grad_layer_16_2norm</td>\n",
       "      <td>[73.9617691040039, 74.3111801147461, 74.687561...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.410423</td>\n",
       "      <td>0.610353</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Train/grad_layer_17_2norm</td>\n",
       "      <td>[74.15571594238281, 74.46347045898438, 74.8021...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.584466</td>\n",
       "      <td>0.676339</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Train/grad_layer_18_2norm</td>\n",
       "      <td>[77.11732482910156, 77.48828125, 77.8407440185...</td>\n",
       "      <td>1099</td>\n",
       "      <td>1.843794</td>\n",
       "      <td>0.787899</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Train/grad_layer_19_2norm</td>\n",
       "      <td>[77.33142852783203, 77.75067138671875, 78.1531...</td>\n",
       "      <td>1099</td>\n",
       "      <td>2.214928</td>\n",
       "      <td>1.113299</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Train/grad_layer_20_2norm</td>\n",
       "      <td>[77.91704559326172, 78.33560180664062, 78.7909...</td>\n",
       "      <td>1099</td>\n",
       "      <td>2.456361</td>\n",
       "      <td>1.439656</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Train/grad_layer_21_2norm</td>\n",
       "      <td>[79.18791961669922, 79.62101745605469, 80.0168...</td>\n",
       "      <td>1099</td>\n",
       "      <td>3.167717</td>\n",
       "      <td>2.151530</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train/grad_layer_22_2norm</td>\n",
       "      <td>[78.55003356933594, 78.92594909667969, 79.3919...</td>\n",
       "      <td>1099</td>\n",
       "      <td>3.638629</td>\n",
       "      <td>2.709837</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train/grad_layer_23_2norm</td>\n",
       "      <td>[78.48815155029297, 78.80691528320312, 79.2251...</td>\n",
       "      <td>1099</td>\n",
       "      <td>5.236060</td>\n",
       "      <td>3.234051</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train/grad_pooler_2norm</td>\n",
       "      <td>[37.847923278808594, 38.695152282714844, 41.42...</td>\n",
       "      <td>1103</td>\n",
       "      <td>16.164764</td>\n",
       "      <td>5.557342</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train/grad_cls_2norm</td>\n",
       "      <td>[105.2564926147461, 105.62910461425781, 106.10...</td>\n",
       "      <td>1099</td>\n",
       "      <td>22.694250</td>\n",
       "      <td>8.092440</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  \\\n",
       "23  Train/grad_embedding_2norm   \n",
       "24    Train/grad_layer_0_2norm   \n",
       "25    Train/grad_layer_1_2norm   \n",
       "26    Train/grad_layer_2_2norm   \n",
       "3     Train/grad_layer_3_2norm   \n",
       "5     Train/grad_layer_4_2norm   \n",
       "7     Train/grad_layer_5_2norm   \n",
       "10    Train/grad_layer_6_2norm   \n",
       "11    Train/grad_layer_7_2norm   \n",
       "12    Train/grad_layer_8_2norm   \n",
       "14    Train/grad_layer_9_2norm   \n",
       "15   Train/grad_layer_10_2norm   \n",
       "17   Train/grad_layer_11_2norm   \n",
       "19   Train/grad_layer_12_2norm   \n",
       "21   Train/grad_layer_13_2norm   \n",
       "20   Train/grad_layer_14_2norm   \n",
       "22   Train/grad_layer_15_2norm   \n",
       "18   Train/grad_layer_16_2norm   \n",
       "16   Train/grad_layer_17_2norm   \n",
       "13   Train/grad_layer_18_2norm   \n",
       "9    Train/grad_layer_19_2norm   \n",
       "8    Train/grad_layer_20_2norm   \n",
       "6    Train/grad_layer_21_2norm   \n",
       "4    Train/grad_layer_22_2norm   \n",
       "2    Train/grad_layer_23_2norm   \n",
       "1      Train/grad_pooler_2norm   \n",
       "0         Train/grad_cls_2norm   \n",
       "\n",
       "                                                value  first_nan_idx  \\\n",
       "23  [103.29421997070312, 103.53217315673828, 103.4...            608   \n",
       "24  [54.35948944091797, 54.52595138549805, 54.6853...            608   \n",
       "25  [241.9202423095703, 243.14605712890625, 244.24...            608   \n",
       "26  [167.96266174316406, 168.76881408691406, 169.7...            608   \n",
       "3   [62.93558883666992, 63.19911575317383, 63.6056...            885   \n",
       "5   [63.615966796875, 63.90384292602539, 64.273933...            950   \n",
       "7   [62.18846893310547, 62.52492904663086, 62.8268...           1099   \n",
       "10  [61.07050704956055, 61.462486267089844, 61.727...           1099   \n",
       "11  [63.3437385559082, 63.75693130493164, 64.03693...           1099   \n",
       "12  [66.45199584960938, 66.84586334228516, 67.0798...           1099   \n",
       "14  [67.0876235961914, 67.46084594726562, 67.72129...           1099   \n",
       "15  [67.27655792236328, 67.66964721679688, 67.8567...           1099   \n",
       "17  [71.53353881835938, 71.94508361816406, 72.1277...           1099   \n",
       "19  [74.53720092773438, 74.94662475585938, 75.2658...           1099   \n",
       "21  [74.5763168334961, 74.93720245361328, 75.35667...           1099   \n",
       "20  [76.73747253417969, 77.13155364990234, 77.5105...           1099   \n",
       "22  [76.26922607421875, 76.68714141845703, 77.1190...           1099   \n",
       "18  [73.9617691040039, 74.3111801147461, 74.687561...           1099   \n",
       "16  [74.15571594238281, 74.46347045898438, 74.8021...           1099   \n",
       "13  [77.11732482910156, 77.48828125, 77.8407440185...           1099   \n",
       "9   [77.33142852783203, 77.75067138671875, 78.1531...           1099   \n",
       "8   [77.91704559326172, 78.33560180664062, 78.7909...           1099   \n",
       "6   [79.18791961669922, 79.62101745605469, 80.0168...           1099   \n",
       "4   [78.55003356933594, 78.92594909667969, 79.3919...           1099   \n",
       "2   [78.48815155029297, 78.80691528320312, 79.2251...           1099   \n",
       "1   [37.847923278808594, 38.695152282714844, 41.42...           1103   \n",
       "0   [105.2564926147461, 105.62910461425781, 106.10...           1099   \n",
       "\n",
       "          607       608  Layer  \n",
       "23  38.097675       NaN     -1  \n",
       "24  13.281496       NaN      0  \n",
       "25   6.631056       NaN      1  \n",
       "26   8.355430       NaN      2  \n",
       "3    3.100649  3.145219      3  \n",
       "5    2.749049  2.426603      4  \n",
       "7    2.052094  1.478170      5  \n",
       "10   1.801063  0.982004      6  \n",
       "11   1.680697  0.878587      7  \n",
       "12   1.578135  0.817214      8  \n",
       "14   1.456332  0.743294      9  \n",
       "15   1.344387  0.700638     10  \n",
       "17   1.358699  0.653256     11  \n",
       "19   1.346042  0.604570     12  \n",
       "21   1.304716  0.583358     13  \n",
       "20   1.306418  0.604090     14  \n",
       "22   1.389920  0.554338     15  \n",
       "18   1.410423  0.610353     16  \n",
       "16   1.584466  0.676339     17  \n",
       "13   1.843794  0.787899     18  \n",
       "9    2.214928  1.113299     19  \n",
       "8    2.456361  1.439656     20  \n",
       "6    3.167717  2.151530     21  \n",
       "4    3.638629  2.709837     22  \n",
       "2    5.236060  3.234051     23  \n",
       "1   16.164764  5.557342     25  \n",
       "0   22.694250  8.092440     25  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "injured-circulation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>120.030708</td>\n",
       "      <td>120.033615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>82.082260</td>\n",
       "      <td>82.081322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>271.936127</td>\n",
       "      <td>271.931732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>183.388824</td>\n",
       "      <td>183.385788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>82.058441</td>\n",
       "      <td>82.057350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>82.012581</td>\n",
       "      <td>82.011475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>82.012695</td>\n",
       "      <td>82.011452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>82.020607</td>\n",
       "      <td>82.019333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>81.990829</td>\n",
       "      <td>81.989540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>81.978439</td>\n",
       "      <td>81.977158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>81.978432</td>\n",
       "      <td>81.977135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>82.015007</td>\n",
       "      <td>82.013657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>81.984474</td>\n",
       "      <td>81.983124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12</td>\n",
       "      <td>81.979126</td>\n",
       "      <td>81.977783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>81.976334</td>\n",
       "      <td>81.975037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>81.989021</td>\n",
       "      <td>81.987701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15</td>\n",
       "      <td>81.977493</td>\n",
       "      <td>81.976204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16</td>\n",
       "      <td>81.973167</td>\n",
       "      <td>81.971832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>81.993065</td>\n",
       "      <td>81.991669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18</td>\n",
       "      <td>81.965317</td>\n",
       "      <td>81.963875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>81.986259</td>\n",
       "      <td>81.984764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>81.986763</td>\n",
       "      <td>81.985313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>82.011086</td>\n",
       "      <td>82.009636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>82.017845</td>\n",
       "      <td>82.016388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23</td>\n",
       "      <td>81.990219</td>\n",
       "      <td>81.988861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>75.174728</td>\n",
       "      <td>75.176628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>18.395102</td>\n",
       "      <td>18.394686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer         607         608\n",
       "2       0  120.030708  120.033615\n",
       "3       0   82.082260   82.081322\n",
       "0       1  271.936127  271.931732\n",
       "1       2  183.388824  183.385788\n",
       "4       3   82.058441   82.057350\n",
       "8       4   82.012581   82.011475\n",
       "9       5   82.012695   82.011452\n",
       "5       6   82.020607   82.019333\n",
       "12      7   81.990829   81.989540\n",
       "19      8   81.978439   81.977158\n",
       "20      9   81.978432   81.977135\n",
       "7      10   82.015007   82.013657\n",
       "17     11   81.984474   81.983124\n",
       "18     12   81.979126   81.977783\n",
       "22     13   81.976334   81.975037\n",
       "14     14   81.989021   81.987701\n",
       "21     15   81.977493   81.976204\n",
       "23     16   81.973167   81.971832\n",
       "11     17   81.993065   81.991669\n",
       "24     18   81.965317   81.963875\n",
       "16     19   81.986259   81.984764\n",
       "15     20   81.986763   81.985313\n",
       "10     21   82.011086   82.009636\n",
       "6      22   82.017845   82.016388\n",
       "13     23   81.990219   81.988861\n",
       "25     25   75.174728   75.176628\n",
       "26     25   18.395102   18.394686"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-actress",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
